{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "## Mathieu Acher\n",
    "# word cloud generator out of tweets (archive)\n",
    "\n",
    "# removal of URLs and @\n",
    "def preprocess_text(rtext):\n",
    "    # https://stackoverflow.com/questions/520031/whats-the-cleanest-way-to-extract-urls-from-a-string-using-python\n",
    "    URL_REGEX = r\"\"\"(?i)\\b((?:https?:(?:/{1,3}|[a-z0-9%])|[a-z0-9.\\-]+[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)/)(?:[^\\s()<>{}\\[\\]]+|\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\))+(?:\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’])|(?:(?<!@)[a-z0-9]+(?:[.\\-][a-z0-9]+)*[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)\\b/?(?!@)))\"\"\"\n",
    "    rtext = re.sub(URL_REGEX, '', rtext) # remove URL\n",
    "    return re.sub(\"@[A-Za-z0-9_]+\", '', rtext)\n",
    "\n",
    "\n",
    "def process_tweets(filename, with_RT=False, after_date=None): \n",
    "    rt = 0\n",
    "    d = pd.read_csv(filename)\n",
    "    full_text = \"\"\n",
    "    for i in range(0, len(d)):\n",
    "        tweet = d.loc[i]\n",
    "        raw_text = tweet['text']\n",
    "        is_real_tweet = not raw_text.startswith(\"RT @\") # a few false positives (~10)\n",
    "        is_real_tweet_bis = np.isnan(tweet['retweeted_status_id']) \n",
    "        if not with_RT and not(is_real_tweet and is_real_tweet_bis): \n",
    "            continue\n",
    "        # else        \n",
    "        tweet_date = tweet['timestamp']\n",
    "        if (after_date is not None and (pd.Timestamp(tweet_date) < pd.Timestamp(after_date))):\n",
    "            continue\n",
    "        rt = rt + 1\n",
    "        cleaned_text = preprocess_text (raw_text)\n",
    "        # print (raw_text, \" \", cleaned_text)\n",
    "        full_text = full_text + cleaned_text \n",
    "    \n",
    "    wordcloud = WordCloud(stopwords=STOPWORDS.update([\"le\", \"will\", \"et\", \"qui\", \"one\", \"très\", \"je\", \"ne\" \"le\", \"de\", \"un\", \"pas\", \"the\", \"pour\", \"la\", \"en\", \"des\", \"now\", \"sur\", \"que\", \"les\", \"c'est\", \"est\", \"dans\", \"du\", \"il\", \"mais\", \"ce\", \"RT\", \"une\", \"cc\", \"avec\"])).generate(full_text)\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "   \n",
    "    print (\"#RT\", rt)\n",
    "            \n",
    "#### location of your archive folder (tweets)\n",
    "basefolder = \"69819418_a9d914455be469ffcc3ec45442c4b6b11406b07f\"\n",
    "filename = \"/Users/macher1/Downloads/\" + basefolder + \"/tweets.csv\"\n",
    "\n",
    "# says \n",
    "## same result \n",
    "process_tweets(filename, with_RT=True, after_date=\"2018-09-07 00:00:01 +0000\")\n",
    "process_tweets(filename, with_RT=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
